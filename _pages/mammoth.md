---
title: "Artificial Intelligence and Machine Learning Group - MAMMOth project"
layout: textlay
excerpt: "AIML Group -- Projects"
sitemap: false
permalink: /projects/mammoth/
---

### MAMMOth (Multi-Attribute, Multimodal Bias Mitigation in AI Systems)

#### 1. Project details
- <b>Project full name: </b> Multi-Attribute, Multimodal Bias Mitigation in AI Systems
- <b>Project acronym: </b>  MAMMOth
- <b>Funding period: </b> starting end 2022 (36 months)
- <b>Funding body: </b> EU under the call HORIZON-CL4-2021-HUMAN-01  (A HUMAN-CENTRED AND ETHICAL DEVELOPMENT OF DIGITAL AND INDUSTRIAL TECHNOLOGIES 2021)
- <b>Homepage: </b> MAMMOth

#### 2. Involved partners
1. Centre for Research and Technology (CERTH), Greece
2. Universität der Bundeswehr München (UniBw), Germany
3. Complexity Science Hub Vienna (CSH), Austria
4. Alma Mater Studiorum - Universita Di Bologna UNIBO, Italy
5. Rijksuniversiteit Groningen (RUG), Netherlands
6. EXUS Software EXUS, Greece
7. Trilateral Research Limited Ireland (TRI-IE), Ireland
8. Trilateral Research Ltd UK (affiliated) (TRI-UK), UK
9. ARIADNEXT (AXT), France
10. CSI Centre for Social Innovation Ltd (CSI), Cyprus
11. Associacio Forum Dona Activa 2010 (DAF), Spain
12. VSI Diversity Development Group (DDG), Lithuania
13. IASIS NGO (IASIS), Greece

#### 3. Team
- Prof. Dr. Eirini Ntoutsi


#### 4. Project overview
Artificial Intelligence (AI) is increasingly employed by businesses, governments, and other organizations to make decisions with farreaching impacts on individuals and society. This offers big opportunities for automation in different sectors and daily life, but at the same time it brings risks for discrimination of minority and marginal population groups on the basis of the so-called protected attributes, like gender, race, and age. Despite the large body of research to date, the proposed methods work in limited settings, under very constrained assumptions, and do not reflect the complexity and requirements of real world applications. To this end, the MAMMOth project focuses on multi-discrimination mitigation for tabular, network and multimodal data. Through its computer science and AI experts, MAMMOth aims at addressing the associated scientific challenges by developing an innovative fairness-aware AI-data driven foundation that provides the necessary tools and techniques for the discovery and mitigation of (multi-)discrimination and ensures the accountability of AI-systems with respect to multiple protected attributes and for traditional tabular data and more complex network and visual data. The project will actively engage with numerous communities of vulnerable and/or underrepresented groups in AI research right from the start, adopting a co-creation approach, to make sure that actual user needs and pains are at the centre of the research agenda and act as guidance to the project's activities. A social science-driven approach supported by social science and ethics experts will guide project research, and a science communication approach will increase the outreach of the outcomes. The project aims to demonstrate through pilots the developed solutions into three relevant sectors of interest: a) finance/loan applications, b) identity verification systems, and c) academic evaluation.

#### 5. Overview of our contributions
UniBw leads WP3 on "Multi-criteria Bias Mitigation Method" and contributes to other WPs.

The objectives of this package are to extend existing definitions of fairness to include multi-dimensional bias/discrimination approaches. Most data are characterised by a number of attributes whose combination might be contributing to biased AI results as current approaches focus on single protected characteristics to examine possible issues and apply mitigation strategies. Further, new methods for identifying and mitigating bias will be developed using multi-dimensional processes.


#### 6. Publications

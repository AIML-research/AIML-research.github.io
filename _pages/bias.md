---
title: "Artificial Intelligence and Machine Learning Group - BIAS project"
layout: textlay
excerpt: "AIML Group -- Projects"
sitemap: false
permalink: /projects/bias/
---

### BIAS: Bias and Discrimination in Big Data and Algorithmic Processing. Philosophical Assessments, Legal Dimensions, and Technical Solutions
<div>
<figure class="fourth">
  <img src="{{ site.url }}{{ site.baseurl }}/images/logopic/logo-bias.jpg" style="width: 250px">  
</figure>
</div>

- <b>Funding: </b> <a href="http://portal.volkswagenstiftung.de/search/projectDetails.do?ref=95037" target="_new">Volkswagen foundation</a> under the call "Artificial Intelligence and the society of the future".
- <b>Project duration: </b> 01.12.2018 — 30.11.2022
- <b>Homepage: </b> <a href="https://www.bias-project.org/">BIAS </a>

#### Team
- Prof. Dr. Eirini Ntoutsi
- MSc. Arjun Roy

#### Challenges & Highlights
AI techniques based on big data and algorithmic processing are increasingly used to guide decisions in important societal spheres, including hiring decisions, university admissions, loan granting, and crime prediction. However, there are strong evidence that algorithms may sometimes amplify rather than eliminate existing bias and discrimination, and thereby have negative effects on social cohesion and on democratic institutions.

Scholarly reflection of these issues has begun but is still in its early stages, and we still lack a comprehensive understanding of how pertinent concepts of bias or discrimination should be interpreted in the context of AI and which technical options to combat bias and discrimination are both realistically possible and normatively justified. The research group “BIAS” examines these issues in an integrated, interdisciplinary project bringing together experts from philosophy, law, and computer science. Our shared research question is: <i>“How can standards of unbiased attitudes and non-discriminatory practices be met in big data analysis and algorithm-based decision-making?”</i>

In approaching this question, the main goal of the computer science research team is <i>to develop concrete technical (algorithmic and statistical) solutions (debiasing strategies, discrimination detection procedures etc.)</i>.
We investigate two directions: multi-fairness-aware learning and fairness-aware multi-task learning.<br>

<i>Multi-fairness-aware learning</i>:<br>
Traditional fairness-aware machine learning mainly focuses on single protected attributes. In reality, though, bias cannot be always attributed to a single attribute, rather multiple protected attributes (referred to as multi-fairness hereafter) can be the root causes of discrimination. This hardens the existing question further as often protected attributes showcase adversarial properties, and tuning for one attribute may intensify discrimination for the other. 

<i>Fairness-aware multi-task learning</i>:<br>
Multi-Task Learning (MTL) aims to leverage useful information contained in multiple tasks to help improve the generalization performance over all tasks. 
Despite the popularity and many applications of MTL, the fairness implications of MTL have only recently come into focus as traditional fairness-aware learning mainly focuses on single task learning (STL). The goal is to develop methods that are able to solve multiple learning tasks simultaneously by considering not only the predictive performance but also the fairness performance on the individual tasks.

#### Related publications
- Le Quy, T., Roy, A., Iosifidis, V., Zhang, W., & Ntoutsi, E. (2022). A survey on datasetsfor fairness-aware machine learning.Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery,e1452.<a href = "https://doi.org/10.1002/widm.1452">https://doi.org/10.1002/widm.1452 </a>
- Le Quy, T., Roy, A., Friege, G., & Ntoutsi, E. (2021). <a href ="https://educationaldatamining.org/EDM2021/virtual/static/pdf/EDM21_paper_184.pdf">Fair-capacitated clustering. </a> In Proceedings of The 14th International Conference on Educational Data Mining (EDM21) (pp. 407-414).
- Cai, Y., Zimek, A., & Ntoutsi, E. (2021, October). <a href = "https://doi.org/10.1109/DSAA53316.2021.9564153"> XPROAX-Local explanations for text classification with progressive neighborhood approximation. </a> In 2021 IEEE 8th International Conference on Data Science and Advanced Analytics (DSAA) (pp. 1-10). IEEE.
- Naumann, P., & Ntoutsi, E. (2021, September). <a href ="https://link.springer.com/chapter/10.1007/978-3-030-86520-7_42"> Consequence-aware Sequential Counterfactual Generation. </a> In Joint European Conference on Machine Learning and Knowledge Discovery in Databases (pp. 682-698). Springer, Cham.
- Hu, T., Iosifidis, V., Liao, W., Zhang, H., Yang, M. Y., Ntoutsi, E., & Rosenhahn, B. (2020, October). <a href = "https://link.springer.com/chapter/10.1007/978-3-030-61527-7_38"> Fairnn-conjoint learning of fair representations for fair decisions. </a> In International Conference on Discovery Science (pp. 581-595). Springer, Cham.
- Ntoutsi, E., Fafalios, P., Gadiraju, U., Iosifidis, V., Nejdl, W., Vidal, M. E., ... & Staab, S. (2020). <a href = "https://onlinelibrary.wiley.com/doi/pdf/10.1002/widm.1356"> Bias in data‐driven artificial intelligence systems—An introductory survey. </a> Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery, 10(3), e1356.
- Zhang, W., & Ntoutsi, E. (2019, August). <a href = "https://dl.acm.org/doi/abs/10.5555/3367032.3367242"> FAHT: an adaptive fairness-aware decision tree classifier </a>. In Proceedings of the 28th International Joint Conference on Artificial Intelligence (pp. 1480-1486).
- Iosifidis, V., & Ntoutsi, E. (2019, November). <a href = "https://dl.acm.org/doi/abs/10.1145/3357384.3357974"> Adafair: Cumulative fairness adaptive boosting. </a> In Proceedings of the 28th ACM International Conference on Information and Knowledge Management (pp. 781-790).
- Iosifidis, V., Fetahu, B., & Ntoutsi, E. (2019, December). <a href = "https://ieeexplore.ieee.org/abstract/document/9006487/"> FAE: A fairness-aware ensemble framework. </a> In 2019 IEEE International Conference on Big Data (Big Data) (pp. 1375-1380). IEEE.
- Iosifidis, V., Tran, T. N. H., & Ntoutsi, E. (2019, August). <a href ="https://link.springer.com/chapter/10.1007/978-3-030-27615-7_20"> Fairness-enhancing interventions in stream classification.</a> In International Conference on Database and Expert Systems Applications (pp. 261-276). Springer, Cham.
- Iosifidis, V., & Ntoutsi, E. (2018). <a href ="http://l3s.de/~iosifidis/Publications/bias_augmentation.pdf">Dealing with bias via data augmentation in supervised learning scenarios. </a> BIAS workshop in conjunction with iConference.
